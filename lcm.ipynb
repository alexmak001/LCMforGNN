{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NR0jgi8qCI1n",
        "outputId": "a7a20182-991c-4ddf-9819-c5de5fff1b2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRUioHP5K0zv"
      },
      "outputs": [],
      "source": [
        "from itertools import chain\n",
        "from math import ceil, log2\n",
        "from copy import deepcopy\n",
        "\n",
        "import numpy as np\n",
        "from torch_geometric.nn.aggr import Aggregation, MaxAggregation\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch_geometric.nn as gnn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "SEED = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- impl. of LCM aggregation using PyG interface\n",
        "- impl. of bitwise emedding layer"
      ],
      "metadata": {
        "id": "xbmDlYIlGM3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LCMAggregation(Aggregation):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        # self.lin = nn.Linear(in_channels, out_channels)\n",
        "        # learnable parameter\n",
        "        self.gru_cell = nn.GRUCell(out_channels, out_channels)\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.gru_cell.reset_parameters()\n",
        "\n",
        "\n",
        "    def _bin_op(self, x, y):\n",
        "        return (self.gru_cell(x, y) + self.gru_cell(y, x)) / 2\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x,\n",
        "        index = None,\n",
        "        ptr = None,\n",
        "        dim_size = None,\n",
        "        dim = -2,\n",
        "        max_num_elements = None,\n",
        "    ):\n",
        "        x, _ = self.to_dense_batch(x, index, ptr, dim_size, dim,\n",
        "                                   max_num_elements=max_num_elements)\n",
        "\n",
        "        # x = self.lin(x).permute(1,0,2)\n",
        "        x = x.permute(1,0,2)\n",
        "        depth = ceil(log2(x.shape[0]))\n",
        "        # losses = []\n",
        "\n",
        "        for _ in range(depth):\n",
        "            x = [\n",
        "                self._bin_op(x[2*i], x[2*i+1]) if 2*i+1 < len(x) else x[2*i]\n",
        "                for i in range(ceil(len(x)/2))\n",
        "            ]\n",
        "\n",
        "        assert len(x) == 1\n",
        "\n",
        "        return x[0]\n",
        "\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
        "                f'{self.out_channels})')\n",
        "\n",
        "\n",
        "\n",
        "class Emb(nn.Module):\n",
        "    def __init__(self, num_bits, emb_dim):\n",
        "        super().__init__()\n",
        "        self.embs = nn.ModuleList([\n",
        "            nn.Embedding(2, emb_dim)\n",
        "            for _ in range(num_bits)\n",
        "        ])\n",
        "\n",
        "    def forward(self, bitvecs):\n",
        "        return torch.stack([emb(b) for emb, b in zip(self.embs, bitvecs.T)]).sum(0)"
      ],
      "metadata": {
        "id": "aPptFi7QSCYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(14, 1)\n",
        "index = torch.tensor([0]*3 + [1]*8 + [2]*2 + [3]*1)\n",
        "\n",
        "aggr = LCMAggregation(1, 1)\n",
        "aggr(x, index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWM6r4nOMZXp",
        "outputId": "ffd28d75-2923-45e0-a41a-080a5e1b9b3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.],\n",
              "        [8.],\n",
              "        [2.],\n",
              "        [1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "verify that LCM agg at least accepts and produces tensors of the correct shapes"
      ],
      "metadata": {
        "id": "vBeD7XeBGpSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_lcm_aggregation():\n",
        "    x = torch.randn(6, 16)\n",
        "    index = torch.tensor([0, 0, 1, 1, 1, 2])\n",
        "\n",
        "    aggr = LCMAggregation(16, 32)\n",
        "    assert str(aggr) == 'LCMAggregation(16, 32)'\n",
        "\n",
        "    out = aggr(x, index)\n",
        "    assert out.size() == (3, 32)\n",
        "\n",
        "test_lcm_aggregation()"
      ],
      "metadata": {
        "id": "jix7lFZ7Clac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "56d19431-bae6-47bb-d904-b089464409ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-dce83ce7f8d9>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtest_lcm_aggregation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-dce83ce7f8d9>\u001b[0m in \u001b[0;36mtest_lcm_aggregation\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maggr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'LCMAggregation(16, 32)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/experimental.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_experimental_mode_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'disable_dynamic_shapes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrequired_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrequired_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/aggr/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m                                      \u001b[0;34mf\"'{dim_size}' but expected \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                                      f\">= '{int(index.max()) + 1}')\")\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/aggr/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-234b7eee86ee>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, index, ptr, dim_size, dim, max_num_elements)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             x = [\n\u001b[0m\u001b[1;32m     37\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bin_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-234b7eee86ee>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             x = [\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bin_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             ]\n",
            "\u001b[0;32m<ipython-input-3-234b7eee86ee>\u001b[0m in \u001b[0;36m_bin_op\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_bin_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1325\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_batched\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m         ret = _VF.gru_cell(\n\u001b[0m\u001b[1;32m   1328\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_hh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: input has inconsistent input_size: got 16 expected 32"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "generate training and validation sets + custom dataloaders"
      ],
      "metadata": {
        "id": "7JK6WuvyGIWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(SEED)\n",
        "\n",
        "\n",
        "bitvecs_to_ints = lambda bitvecs: \\\n",
        "  (bitvecs * torch.pow(2, torch.arange(num_bits).flip(0)).reshape(1,-1)).sum(-1)\n",
        "\n",
        "num_bits = 8\n",
        "\n",
        "class Random2ndMinimumDataset(Dataset):\n",
        "    def __init__(self, dataset_sz, num_bits, multiset_sz):\n",
        "        self.generate_dataset(dataset_sz, num_bits, multiset_sz)\n",
        "\n",
        "    def generate_dataset(self, dataset_sz, num_bits, multiset_sz):\n",
        "        self.dataset = []\n",
        "        for _ in range(dataset_sz):\n",
        "            # randomly sample multiset size\n",
        "            if isinstance(multiset_sz, tuple):\n",
        "              sz = torch.randint(*multiset_sz, (1,))\n",
        "            else:\n",
        "              sz = multiset_sz\n",
        "\n",
        "            # randomly sample a multiset of integers of size `sz`, encoded as bit-vectors\n",
        "            bitvecs = torch.randint(0, 2, (sz, num_bits))\n",
        "\n",
        "            # convert bit-vectors to integers\n",
        "            ints = bitvecs_to_ints(bitvecs)\n",
        "\n",
        "            # find the second smallest element in the multiset, which is the target\n",
        "            target_idx = torch.topk(ints, 2).indices[-1]\n",
        "            target = bitvecs[target_idx].float()\n",
        "\n",
        "            self.dataset += [(bitvecs, target)]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.dataset[i]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "\n",
        "trainset = Random2ndMinimumDataset(2**16, num_bits, (2, 16+1))\n",
        "validset = Random2ndMinimumDataset(2**10, num_bits, 32)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# dataloaders\n",
        "\n",
        "def collate_fn(samples):\n",
        "    x = torch.cat([samp[0] for samp in samples])\n",
        "    y = torch.stack([samp[1] for samp in samples])\n",
        "    sizes = torch.tensor([samp[0].shape[0] for samp in samples])\n",
        "    return x, y, sizes\n",
        "\n",
        "train_dl = DataLoader(trainset, batch_size=2**5, collate_fn=collate_fn, shuffle=True)\n",
        "valid_dl = DataLoader(validset, batch_size=len(validset), collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "mi2AhcO1Cp4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (x, y) in enumerate(iter(trainset)):\n",
        "  print(x.shape, y.shape)\n",
        "  if i >= 5:\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jBtxkAhEBAm",
        "outputId": "0dec892c-225c-4732-90e5-6e614bc9cfba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([14, 8]) torch.Size([8])\n",
            "torch.Size([8, 8]) torch.Size([8])\n",
            "torch.Size([5, 8]) torch.Size([8])\n",
            "torch.Size([7, 8]) torch.Size([8])\n",
            "torch.Size([6, 8]) torch.Size([8])\n",
            "torch.Size([13, 8]) torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dl = DataLoader(trainset, batch_size=3, collate_fn=collate_fn)\n",
        "x, y, sizes = next(iter(dl))\n",
        "\n",
        "# print(sizes)\n",
        "a = [ [i] * sz for i, sz in enumerate(sizes) ]\n",
        "\n",
        "print(a)\n",
        "print()\n",
        "print(chain(*a))\n",
        "print()\n",
        "print(list(chain(*a)))\n",
        "print()\n",
        "print(torch.tensor(list(chain(*a))))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MN--lQSIHVI8",
        "outputId": "3326fee4-a9d6-40b6-f0d7-04ae6e396cc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1], [2, 2, 2, 2, 2]]\n",
            "\n",
            "<itertools.chain object at 0x7f3dae4edc30>\n",
            "\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2]\n",
            "\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
            "        2, 2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = [0,0,0]\n",
        "b = [1,1]\n",
        "\n",
        "for x in chain(*[a, b]):\n",
        "  print(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF9zcI9XI0Jr",
        "outputId": "6083d06c-fc9c-4c67-9d83-20b5436d17d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0]\n",
            "[1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f(*args):\n",
        "  print(args)\n",
        "\n",
        "f(*(1,2,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UONw-Iy_J-Sf",
        "outputId": "3f562486-5f01-4eb9-83fa-c2e3b1a1d399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "create model, optimizer, and loss function"
      ],
      "metadata": {
        "id": "pMRLF80vGCQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(SEED)\n",
        "\n",
        "\n",
        "h = 128\n",
        "\n",
        "# n = length of list\n",
        "# (n, 8) -> (n, 128) -> (1, 128) -> (1, 8)\n",
        "\n",
        "# label (y): [1, 0, 1, 1]\n",
        "# pred  (x): [.1, .2, .9, .9]\n",
        "# BCE loss: for each bit, compute ylogx + (1-y)log(1-x), then sum\n",
        "# -loss = [ 1log(.1) + 0log(.9) ] + [ 0log(.2) + 1log(.8) ] + [ 1log(.9) + 0log(.1) ] + [ 1log(.9) + 0log(.1) ]\n",
        "#  loss = 2.74\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# class Net(nn.Module):\n",
        "#   def __init__(self):\n",
        "#     self.enc = nn.Sequential(\n",
        "#         Emb(num_bits, h),\n",
        "#         nn.Linear(h, h),\n",
        "#         nn.Dropout(.5),\n",
        "#         nn.GELU()) #, nn.Linear(h, h), nn.GELU())\n",
        "\n",
        "#     self.agg = LCMAggregation(h, h)\n",
        "\n",
        "#     self.dec = nn.Sequential(\n",
        "#         nn.Linear(h, h),\n",
        "#         nn.Dropout(.5),\n",
        "#         nn.GELU(),\n",
        "#         nn.Linear(h, num_bits)) #, nn.Sigmoid())\n",
        "\n",
        "#   def forward(self, x, index):\n",
        "#     x = self.enc(x)\n",
        "#     x = self.agg(x, index)\n",
        "#     x = self.dec(x)\n",
        "#     return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "enc = nn.Sequential(\n",
        "    Emb(num_bits, h),\n",
        "    nn.Linear(h, h),\n",
        "    nn.Dropout(.5),\n",
        "    nn.GELU()) #, nn.Linear(h, h), nn.GELU())\n",
        "\n",
        "agg = LCMAggregation(h, h)\n",
        "\n",
        "dec = nn.Sequential(\n",
        "    nn.Linear(h, h),\n",
        "    nn.Dropout(.5),\n",
        "    nn.GELU(),\n",
        "    nn.Linear(h, num_bits)) #, nn.Sigmoid())\n",
        "\n",
        "net = gnn.Sequential('x, index', [\n",
        "    (enc, 'x -> x'),\n",
        "    (agg, 'x, index -> x'),\n",
        "    (dec, 'x -> x')\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# using `BCEWithLogitsLoss` instead of `BCELoss`+Sigmoid for numerical stability\n",
        "criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
        "\n",
        "opt = torch.optim.Adam(params=net.parameters(), lr=1e-4)\n",
        "\n"
      ],
      "metadata": {
        "id": "tw7YRQpmFyU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(SEED)\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "net.to(device)\n",
        "\n",
        "best_state_dict = None\n",
        "best_valid_acc = 0\n",
        "\n",
        "print('Beginning training.')\n",
        "\n",
        "for ep in range(1):\n",
        "    losses = []\n",
        "    for i, (x, y, sizes) in enumerate(train_dl):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        index = torch.tensor(list(chain(*[\n",
        "            [i] * sz for i, sz in enumerate(sizes)\n",
        "        ]))).to(device)\n",
        "\n",
        "        pred = net(x, index)\n",
        "\n",
        "        # print(pred.shape, y.shape, criterion(pred, y).shape)\n",
        "\n",
        "        loss = criterion(pred, y).sum(-1).mean()\n",
        "        print(loss)\n",
        "\n",
        "\n",
        "\n",
        "        losses += [loss.item()]\n",
        "        print(loss.item())\n",
        "        break\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "    # losses = np.array(losses)\n",
        "    # loss_mean, loss_std = losses.mean(), losses.std()\n",
        "\n",
        "    # accs = []\n",
        "    # for x, y, sizes in valid_dl:\n",
        "    #     x = x.to(device)\n",
        "    #     y = y.to(device)\n",
        "    #     index = torch.tensor(list(chain(*[\n",
        "    #         [i] * sz for i, sz in enumerate(sizes)\n",
        "    #     ]))).to(device)\n",
        "\n",
        "    #     pred = nn.functional.sigmoid(net(x, index)).round().squeeze()\n",
        "    #     accuracy = ((pred != y).sum(-1) == 0).sum() / y.shape[0]\n",
        "    #     accs += [accuracy.item()]\n",
        "    # mean_acc = sum(accs) / len(accs)\n",
        "    # if mean_acc > best_valid_acc:\n",
        "    #     best_state_dict = deepcopy(net.state_dict())\n",
        "    #     best_valid_acc = mean_acc\n",
        "\n",
        "    # print(f'ep {ep+1:04d}: loss=[{loss_mean:.4f}, {loss_std:.4f}], acc={mean_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RA5Y71DYSfQQ",
        "outputId": "a357eca1-1469-40e6-dba1-931c812ece69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beginning training.\n",
            "tensor(5.5676, grad_fn=<MeanBackward0>)\n",
            "5.567600250244141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hf8cl8DgMgK4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}